{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "external-lithuania",
   "metadata": {},
   "source": [
    "### User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "arbitrary-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "retailer = 'pure'\n",
    "sql = 'pure_txns.sql'\n",
    "offer_name = 'free coffee yellow'\n",
    "measurement_period = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-variable",
   "metadata": {},
   "source": [
    "### Packages and definitions needed for python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "japanese-minnesota",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jennamiles/.pyenv/versions/3.9.1/lib/python3.9/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# install required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.database import query_from_file\n",
    "import datetime\n",
    "import time\n",
    "import plotly.express as px\n",
    "import psutil\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "path = '/Users/jennamiles/Documents/credentials'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "charged-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is from database.py\n",
    "#need to update in utils because of directory issue\n",
    "import os\n",
    "from psycopg2 import connect\n",
    "from pandas import read_sql\n",
    "\n",
    "def query(sql_statement: str, **kwargs):\n",
    "    with open(f'{path}', 'r') as credentials:\n",
    "        connection = connect(credentials.read())\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        if len(kwargs) > 0:\n",
    "            dataframe = read_sql(sql_statement.format(**kwargs), connection)\n",
    "        else:\n",
    "            dataframe = read_sql(sql_statement, connection)\n",
    "\n",
    "        assert len(dataframe) > 0, 'query returned no results'\n",
    "        return dataframe\n",
    "    \n",
    "def query_from_file(sql_file: str, **kwargs):\n",
    "    with open(sql_file, 'r') as f:\n",
    "        return query(f.read(), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-essence",
   "metadata": {},
   "source": [
    "### Read in transactions for retailer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "reasonable-contest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query took 4.67 seconds\n"
     ]
    }
   ],
   "source": [
    "#read in pure data from SQL query:\n",
    "start = time.time()\n",
    "df = query_from_file(sql)\n",
    "end = time.time()\n",
    "query_time = end-start\n",
    "print(f\"Query took {query_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-occupation",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "- Creates new **date** variables that will be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "chicken-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional date columns that will be useful \n",
    "df['date'] = df['transaction_date'].dt.date\n",
    "df['day'] = df['transaction_date'].dt.isocalendar().day\n",
    "df['week'] = df['transaction_date'].dt.isocalendar().week\n",
    "df['week_start'] = (df['transaction_date'] - pd.TimedeltaIndex(df['transaction_date'].dt.dayofweek, unit='D')).dt.date\n",
    "df['month'] = df['transaction_date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-bicycle",
   "metadata": {},
   "source": [
    "- Change data types where necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "angry-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change price to a numeric variable \n",
    "df['price'] = pd.to_numeric(df['item_price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-arizona",
   "metadata": {},
   "source": [
    "- Creates a variable that indicates the **receipt number** for that customer\n",
    "- This will be used to segments new and existing customers\n",
    "- Warning - we can only see if they are new customers within Flux, so they may have a receipt count of 1 even though transacted before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "juvenile-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_receipts = df[['customer_id','receipt_id','total_amount','transaction_date','date','month','week','location_id']].drop_duplicates().sort_values(['customer_id','transaction_date'])\n",
    "df_receipts['receipt_count'] = df_receipts.groupby(['customer_id'])['receipt_id'].cumcount()+1\n",
    "df = pd.merge(df, df_receipts[['receipt_count','customer_id','receipt_id']], on = ['customer_id','receipt_id'], how = 'left' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-square",
   "metadata": {},
   "source": [
    "- identify transactions on the chosen offer\n",
    "- save the receipts containing the offer to an array to reference another time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "simple-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_offer = df[df['name'] == 'Free Coffee YELLOW'].copy()\n",
    "redemption_receipts = df_offer['receipt_id'].unique()\n",
    "redeemers = df_offer['customer_id'].unique()\n",
    "redemption_count = len(redemption_receipts)\n",
    "redeemer_count = len(redeemers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-raleigh",
   "metadata": {},
   "source": [
    "- assign start and end dates of the offer to objects to reference in code\n",
    "- assign the number of days, weeks and months an offer was live for to objects to reference in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "illegal-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_min = df_offer['date'].min()\n",
    "date_max = df_offer['date'].max()\n",
    "days_live = (date_max - date_min).days\n",
    "weeks_live = round(np.floor(days_live/7))\n",
    "months_live = round(np.floor(weeks_live/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-stick",
   "metadata": {},
   "source": [
    "- identify all transactions at retailer while the offer was live\n",
    "- segment customers that transacted during the offer period into customers acquired on offer and previous customers = acquired_previous\n",
    "- segment customers that transacted into new and existing before the offer period start date = new_existing\n",
    "- segment customers into customers that redeemed the offer or not\n",
    "- also going to provide a view of acquired, new_not_acquired, existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "instrumental-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_live = df[(df['date']<=date_max) & (df['date']>=date_min)].copy()\n",
    "\n",
    "new_customers = df_live[df_live.receipt_count== 1].customer_id.unique()\n",
    "acquired_customers = df_live[(df_live['receipt_id'].isin(redemption_receipts))& (df_live.receipt_count==1)]['customer_id'].unique()\n",
    "\n",
    "df_live['redemption_segment'] = np.where(df_live['customer_id'].isin(redeemers),'redeemer','non-redeemer')\n",
    "df_live['acquired_previous'] = np.where(df_live['customer_id'].isin(acquired_customers),'acquired','previous')\n",
    "df_live['new_existing'] = np.where(df_live['customer_id'].isin(new_customers),'new','existing')\n",
    "df_live['acquired_new_existing'] = np.where(df_live['customer_id'].isin(acquired_customers),'acquired',df_live['new_existing'])\n",
    "df_live['acquired_new_existing'] = df_live['acquired_new_existing'].str.replace('new','new_not_acquired')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-photograph",
   "metadata": {},
   "source": [
    "- create a df that holds only the receipt information and not the sku data too, with segments included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "systematic-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_live_receipts = df_live[['customer_id', 'receipt_id', 'total_amount', 'price', 'redemption_segment', 'acquired_previous', 'new_existing', 'acquired_new_existing','transaction_date','receipt_count','date','week_start']].copy().drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-encounter",
   "metadata": {},
   "source": [
    "- add in a variable that holds **basket size**\n",
    "- don't want to include in basket size any freebies or £0 items, such as the milk chosen, or any discounts that aren't an item, such as 50p off for using a reusable cup\n",
    "- it is tricky because the true offers, such as free coffe first appear as an item and then the price is taken off. \n",
    "- The item price being taken off should match that provided on the receipt for it to be an offer and not just a discounts, e.g. reusable cup 50p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "backed-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a receipt_price_count variable, so can flag if multiple used on one receipt\n",
    "df['receipt_price_count'] = df.groupby(['receipt_id','price']).cumcount()+1\n",
    "#identify the discounts\n",
    "discounts = pd.DataFrame(df[df['price']<0][['receipt_id','price','receipt_price_count']])\n",
    "discounts['price'] = discounts['price']*-1\n",
    "discounts['offer_flag'] = '1'\n",
    "#reattach the discounts onto transactions to match the item where freebie has been given\n",
    "#now anything bought on an offer should be flagged \n",
    "df = pd.merge(df, discounts, on=['receipt_id','price','receipt_price_count'], how = 'left')\n",
    "df.fillna('0', inplace = True)\n",
    "#count the paid-for items on each receipt\n",
    "#this will still include the initial proe of items that were taken off the final receipt\n",
    "receipt_item_count = pd.DataFrame(df[(df['price']>0) & (df['offer_flag']=='0')].groupby('receipt_id').count()['item_id']).reset_index()\n",
    "receipt_item_count.columns = ['receipt_id','adjusted_basket_size']\n",
    "#attach onto receipts from the offer period\n",
    "df_live = pd.merge(df_live,receipt_item_count, on = 'receipt_id',how = 'left') \n",
    "df_live.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-landing",
   "metadata": {},
   "source": [
    "# Results\n",
    "### Segment counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "technical-difference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>unique customers</th>\n",
       "      <th>unique receipts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>redemption_segment</th>\n",
       "      <th>acquired_previous</th>\n",
       "      <th>new_existing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">non-redeemer</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">previous</th>\n",
       "      <th>existing</th>\n",
       "      <td>3134</td>\n",
       "      <td>13922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>3896</td>\n",
       "      <td>6741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">redeemer</th>\n",
       "      <th>acquired</th>\n",
       "      <th>new</th>\n",
       "      <td>22</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">previous</th>\n",
       "      <th>existing</th>\n",
       "      <td>91</td>\n",
       "      <td>1229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>44</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   unique customers  \\\n",
       "redemption_segment acquired_previous new_existing                     \n",
       "non-redeemer       previous          existing                  3134   \n",
       "                                     new                       3896   \n",
       "redeemer           acquired          new                         22   \n",
       "                   previous          existing                    91   \n",
       "                                     new                         44   \n",
       "\n",
       "                                                   unique receipts  \n",
       "redemption_segment acquired_previous new_existing                   \n",
       "non-redeemer       previous          existing                13922  \n",
       "                                     new                      6741  \n",
       "redeemer           acquired          new                        54  \n",
       "                   previous          existing                 1229  \n",
       "                                     new                       488  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_receipt_counts = df_live.groupby(['redemption_segment','acquired_previous','new_existing']).nunique()[['customer_id','receipt_id']]\n",
    "customer_receipt_counts.columns = ['unique customers','unique receipts']\n",
    "customer_receipt_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-earthquake",
   "metadata": {},
   "source": [
    "### Segment percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-omega",
   "metadata": {},
   "source": [
    "- What percent of customers using the offer are acquired customers vs customers that had already transacted at the retailer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "whole-plane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The % split of redeemers by customer segment is:\n",
      "acquired_previous  new_existing\n",
      "acquired           new             14.012739\n",
      "previous           existing        57.961783\n",
      "                   new             28.025478\n",
      "Name: unique customers, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "customer_pcent = (customer_receipt_counts.loc['redeemer']['unique customers']/(customer_receipt_counts.loc['redeemer']['unique customers'].sum()))*100\n",
    "print('The % split of redeemers by customer segment is:')\n",
    "print(customer_pcent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-nudist",
   "metadata": {},
   "source": [
    "- what % of customers transacting per week at the retailer are new that week vs previous?\n",
    "- use the previous 4 weeks worth of transactions prior to the offer\n",
    "- we will use this as a baseline to compare the offer to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "useful-basin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline of transacting customers that are new per week is: 51.63%\n"
     ]
    }
   ],
   "source": [
    "df_pre = df_receipts[df_receipts.date < date_min].copy()\n",
    "baseline_pre = df_pre[df_pre['receipt_count']==1].groupby(['week','receipt_count']).nunique()[['customer_id']]/df_pre.groupby('week').nunique()[['customer_id']].tail(4)\n",
    "baseline_new_pcent = baseline_pre['customer_id'].mean()*100\n",
    "print(f'The baseline of transacting customers that are new per week is: {baseline_new_pcent:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-ethernet",
   "metadata": {},
   "source": [
    "- *would be good here to know how much this varies - does the offer fall between 2sd of the ussual % customers? Is is truly different? or do we only care about having a comparison?*\n",
    "- *or some sort of significance test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "contained-grenada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>customer_id_nunique</th>\n",
       "      <th>weekly_ATF</th>\n",
       "      <th>ATF_offer_period</th>\n",
       "      <th>ATV</th>\n",
       "      <th>weekly_ACV</th>\n",
       "      <th>ACV_offer_period</th>\n",
       "      <th>ABS</th>\n",
       "      <th>yearly_ATF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>redemption_segment</th>\n",
       "      <th>acquired_previous</th>\n",
       "      <th>new_existing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">non-redeemer</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">previous</th>\n",
       "      <th>existing</th>\n",
       "      <td>3134</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.118333</td>\n",
       "      <td>0.252219</td>\n",
       "      <td>17.295</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.520833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>3896</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.950000</td>\n",
       "      <td>0.129573</td>\n",
       "      <td>8.885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">redeemer</th>\n",
       "      <th>acquired</th>\n",
       "      <th>new</th>\n",
       "      <td>22</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.411000</td>\n",
       "      <td>0.280875</td>\n",
       "      <td>19.260</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">previous</th>\n",
       "      <th>existing</th>\n",
       "      <td>91</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>0.926042</td>\n",
       "      <td>63.500</td>\n",
       "      <td>1.470588</td>\n",
       "      <td>6.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>44</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.074308</td>\n",
       "      <td>1.188031</td>\n",
       "      <td>81.465</td>\n",
       "      <td>1.650433</td>\n",
       "      <td>4.562500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   customer_id_nunique  \\\n",
       "redemption_segment acquired_previous new_existing                        \n",
       "non-redeemer       previous          existing                     3134   \n",
       "                                     new                          3896   \n",
       "redeemer           acquired          new                            22   \n",
       "                   previous          existing                       91   \n",
       "                                     new                            44   \n",
       "\n",
       "                                                   weekly_ATF  \\\n",
       "redemption_segment acquired_previous new_existing               \n",
       "non-redeemer       previous          existing        0.029167   \n",
       "                                     new             0.014583   \n",
       "redeemer           acquired          new             0.021875   \n",
       "                   previous          existing        0.131250   \n",
       "                                     new             0.087500   \n",
       "\n",
       "                                                   ATF_offer_period       ATV  \\\n",
       "redemption_segment acquired_previous new_existing                               \n",
       "non-redeemer       previous          existing                   2.0  5.118333   \n",
       "                                     new                        1.0  4.950000   \n",
       "redeemer           acquired          new                        1.5  3.411000   \n",
       "                   previous          existing                   9.0  4.550000   \n",
       "                                     new                        6.0  5.074308   \n",
       "\n",
       "                                                   weekly_ACV  \\\n",
       "redemption_segment acquired_previous new_existing               \n",
       "non-redeemer       previous          existing        0.252219   \n",
       "                                     new             0.129573   \n",
       "redeemer           acquired          new             0.280875   \n",
       "                   previous          existing        0.926042   \n",
       "                                     new             1.188031   \n",
       "\n",
       "                                                   ACV_offer_period       ABS  \\\n",
       "redemption_segment acquired_previous new_existing                               \n",
       "non-redeemer       previous          existing                17.295  1.500000   \n",
       "                                     new                      8.885  1.000000   \n",
       "redeemer           acquired          new                     19.260  1.000000   \n",
       "                   previous          existing                63.500  1.470588   \n",
       "                                     new                     81.465  1.650433   \n",
       "\n",
       "                                                   yearly_ATF  \n",
       "redemption_segment acquired_previous new_existing              \n",
       "non-redeemer       previous          existing        1.520833  \n",
       "                                     new             0.760417  \n",
       "redeemer           acquired          new             1.140625  \n",
       "                   previous          existing        6.843750  \n",
       "                                     new             4.562500  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab counts, ATF, ATV  and Basket Size per group \n",
    "\n",
    "#first group by customer\n",
    "agg = df_live.groupby(['redemption_segment','acquired_previous','new_existing','customer_id']).agg({'receipt_id':['nunique']\n",
    "                                                                                        ,'total_amount':['sum','mean']\n",
    "                                                                                        ,'adjusted_basket_size':['mean']})\n",
    "agg.columns=agg.columns.map('_'.join)\n",
    "agg.columns = ['frequency','total_amount','amount','adjusted_basket_size']\n",
    "agg.reset_index(inplace = True)\n",
    "#then grab metrics\n",
    "agg2 = agg.groupby(['redemption_segment','acquired_previous','new_existing']).agg({'customer_id'  : ['nunique']\n",
    "                                                                    ,'frequency'  : ['mean','median']\n",
    "                                                                    ,'total_amount': ['sum','mean','median']\n",
    "                                                                    , 'amount':['mean','median']\n",
    "                                                                    , 'adjusted_basket_size':['mean','median']\n",
    "                                                                           })\n",
    "agg2.columns=agg2.columns.map('_'.join)\n",
    "agg2['weekly_ATF'] = agg2['frequency_median']/(days_live/7)\n",
    "agg2['yearly_ATF'] = (agg2['frequency_median']/(days_live))*365\n",
    "agg2['ATF_offer_period'] = agg2['frequency_median']\n",
    "agg2['ATV'] = agg2['amount_median']/100 #using median as less sensitive to outliers\n",
    "agg2['weekly_ACV'] = (agg2['total_amount_median']/(days_live/7))/100\n",
    "agg2['ACV_offer_period'] = (agg2['total_amount_median'])/100\n",
    "agg2['ABS'] = agg2['adjusted_basket_size_median']\n",
    "summary_metrics = agg2[['customer_id_nunique','weekly_ATF','ATF_offer_period','ATV','weekly_ACV','ACV_offer_period','ABS','yearly_ATF']]\n",
    "summary_metrics\n",
    "#note haven't separated out the custoomers acquired ON the offer here\n",
    "#treating new customers during offer measurement period as all new even iff not acquired on the offer\n",
    "#this is easier to measure\n",
    "#just need to make sure it is clesar when displaying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-maria",
   "metadata": {},
   "source": [
    "## Redemptions Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "imperial-albania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of redemptions =  308\n",
      "The total number of unique customers that used the offer = 157\n",
      "The numer of redemptions per customer = 1.96\n",
      "\n",
      "\n",
      "14% of redeemers (22 customers) are new customers that were acquired on the offer, meaning their first transaction was using the offer\n",
      "86% of redeemers are previous customers\n",
      "\n",
      "\n",
      "The baseline % of weekly new customers is 51.63% \n",
      "(This is the average % of customers that are new based on 4 weeks pre offer start)\n",
      "The % of weekly new customers during the offer period is 2523.57% \n",
      "\n",
      "\n",
      "Offer redeemers have an absolute % difference of -38% new customers compared to the baseline\n"
     ]
    }
   ],
   "source": [
    "#all redemptions\n",
    "total_redemptions = len(df_offer)\n",
    "#all redeemers\n",
    "total_cust = agg2.loc['redeemer'].customer_id_nunique.sum()\n",
    "#redemptions per customer\n",
    "redemptions_per_customer = total_redemptions/total_cust\n",
    "\n",
    "#previous retailer customers\n",
    "previous_volume = agg2.loc['redeemer'].loc['previous'].customer_id_nunique.sum()\n",
    "#retailer acquisitions - made first transacgion on the offer\n",
    "acquisitions_volume = df_live[df_live.acquired_previous == 'acquired']['customer_id'].nunique()\n",
    "#total new customers\n",
    "new_volume = df_live[df_live.new_existing == 'new']['customer_id'].nunique()\n",
    "\n",
    "#percentages\n",
    "previous_pcent = (previous_volume/total_cust)*100\n",
    "acquisitions_pcent = (acquisitions_volume/total_cust)*100\n",
    "new_pcent = (new_volume/total_cust)*100\n",
    "baseline_diff = new_cust_pcent - baseline_new_pcent\n",
    "\n",
    "#print results\n",
    "print(f'The total number of redemptions =  {total_redemptions}')\n",
    "print(f'The total number of unique customers that used the offer = {total_cust}')\n",
    "print(f'The numer of redemptions per customer = {redemptions_per_customer:.2f}')\n",
    "print('\\n')\n",
    "print(f'{acquisitions_pcent:.0f}% of redeemers ({acquisitions_volume} customers) are new customers that were acquired on the offer, meaning their first transaction was using the offer')\n",
    "print(f'{previous_pcent:.0f}% of redeemers are previous customers')\n",
    "print('\\n')\n",
    "print(f'The baseline % of weekly new customers is {baseline_new_pcent:.2f}% \\n(This is the average % of customers that are new based on 4 weeks pre offer start)')\n",
    "print(f'The % of weekly new customers during the offer period is {new_pcent:.2f}% ')\n",
    "print('\\n')\n",
    "print(f'Offer redeemers have an absolute % difference of {baseline_diff:.0f}% new customers compared to the baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-noise",
   "metadata": {},
   "source": [
    "## Frequency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_metrics = summary_metrics['weekly_ATF']\n",
    "\n",
    "\n",
    "ATF_redeemer = agg[agg['offer_segment']=='redeemer']['frequency'].median()\n",
    "ATF_non_redeemer = agg[agg['offer_segment']=='non-redeemer']['frequency'].median()\n",
    "\n",
    "ATF_redeemer_weekly = agg[agg['offer_segment']=='redeemer']['frequency'].median()/(d/7)\n",
    "ATF_non_redeemer_weekly = agg[agg['offer_segment']=='non-redeemer']['frequency'].median()/(d/7)\n",
    "\n",
    "print(f'Redeemers of the offer transacted on average {ATF_redeemer:.0f} times during the offer period')\n",
    "print(f'Non-redeemers of the offer transacted on average {ATF_non_redeemer:.0f} times during the offer period')\n",
    "print('\\n')\n",
    "print(f'Redeemers of the offer transacted on average {ATF_redeemer_weekly:.2f} times PER WEEK during the offer period')\n",
    "print(f'Non-redeemers of the offer transacted on average {ATF_non_redeemer_weekly:.2f} times PER WEEK during the offer period')\n",
    "print('\\n')\n",
    "\n",
    "print('More detailed breakdown of weekly ATF:')\n",
    "print(f_metrics)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-copper",
   "metadata": {},
   "source": [
    "## Repeat Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need this as a view of x many days after their first purchase\n",
    "df_acq_txns = df_during[df_during.new_segment == 'acquired'][['customer_id','date','count']].copy()\n",
    "df_new_not_acq = df_during[df_during.new_segment == 'new'][['customer_id','date','count']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acq_txns['lagged_date'] = df_acq_txns.groupby('customer_id')['date'].shift(1)\n",
    "df_acq_txns['date_diff'] = (df_acq_txns['date'] - df_acq_txns['lagged_date']).dt.days\n",
    "df_acq_txns['week_diff'] = np.ceil(df_acq_txns.date_diff/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_not_acq['lagged_date'] = df_new_not_acq.groupby('customer_id')['date'].shift(1)\n",
    "df_new_not_acq['date_diff'] = (df_new_not_acq['date'] - df_new_not_acq['lagged_date']).dt.days\n",
    "df_new_not_acq['week_diff'] = np.ceil(df_new_not_acq.date_diff/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_by_week = pd.DataFrame(df_acq_txns[df_acq_txns['count']==2].groupby('week_diff').nunique()['customer_id']).reset_index().cumsum()\n",
    "repeat_by_week['pcent_of_acquisitions'] = (repeat_by_week['customer_id']/len(offer_acquisitions))*100\n",
    "repeat_by_week.columns = ['weeks_since_transaction','cumulative_made_second_transaction','pcent']\n",
    "repeat_by_week.set_index('weeks_since_transaction', inplace = True)\n",
    "repeat_by_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all customer new not acquired on the offer\n",
    "new_count = summary_metrics.loc['non-redeemer'].loc['new']['customer_id_nunique']+ summary_metrics.loc['redeemer'].loc['new']['customer_id_nunique']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at cumulative repeat for all new customers not acquired\n",
    "repeat_by_week2 = pd.DataFrame(df_new_not_acq[df_new_not_acq['count']==2].groupby('week_diff').nunique()['customer_id']).reset_index().cumsum()\n",
    "repeat_by_week2['pcent_of_acquisitions'] = (repeat_by_week2['customer_id']/new_count)*100\n",
    "repeat_by_week2.columns = ['weeks_since_transaction','cumulative_made_second_transaction','pcent']\n",
    "repeat_by_week2.set_index('weeks_since_transaction', inplace = True)\n",
    "repeat_by_week2 = repeat_by_week2.loc[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = repeat_by_week.index.values\n",
    "y1 = repeat_by_week['pcent']\n",
    "x2 = repeat_by_week2.index.values\n",
    "y2 = repeat_by_week2['pcent']\n",
    "plt.plot(x1,y1,marker='o', linestyle='dashed',linewidth=2, markersize=12, label = 'acquired')\n",
    "plt.plot(x2,y2,marker='o', linestyle='dashed',linewidth=2, markersize=12, label = 'not acquired', color = 'mint')\n",
    "plt.ylabel('cumulative % of offer repeat customers', size = 30)\n",
    "plt.xlabel('# weeks since first transaction', size = 30)\n",
    "plt.legend(fontsize = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_8wk_repeat = repeat_by_week2.loc[:8]['pcent'].max()\n",
    "acq_8wk_repeat = repeat_by_week.loc[:8]['pcent'].max()\n",
    "\n",
    "\n",
    "print(f'Not acquired: 8 weeks after first transaction {new_8wk_repeat:.0f}% of customers had made a repeat purchase')\n",
    "print(f'Acquired: 8 weeks after first transaction {acq_8wk_repeat:.0f}% of customers had made a repeat purchase')\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_by_week2.loc[:8]['cumulative_made_second_transaction'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase3= pd.DataFrame(df_acq_txns[df_acq_txns['count']==3].groupby('week_diff').nunique()['customer_id']).reset_index().cumsum()\n",
    "purchase3['pcent_of_acquisitions'] = (purchase3['customer_id']/len(offer_acquisitions))*100\n",
    "purchase3.columns = ['weeks_since_transaction','cumulative_made_second_transaction','pcent']\n",
    "purchase3.set_index('weeks_since_transaction', inplace = True)\n",
    "purchase3\n",
    "\n",
    "#look at cumulative repeat for all new customers not acquired\n",
    "purchase3b = pd.DataFrame(df_new_not_acq[df_new_not_acq['count']==3].groupby('week_diff').nunique()['customer_id']).reset_index().cumsum()\n",
    "purchase3b['pcent_of_acquisitions'] = (purchase3b['customer_id']/new_count)*100\n",
    "purchase3b.columns = ['weeks_since_transaction','cumulative_made_second_transaction','pcent']\n",
    "purchase3b.set_index('weeks_since_transaction', inplace = True)\n",
    "purchase3b = purchase3b.loc[:12]\n",
    "\n",
    "new_8wk_repeat3 = purchase3b.loc[:8]['pcent'].max()\n",
    "acq_8wk_repeat3 = purchase3.loc[:8]['pcent'].max()\n",
    "\n",
    "print('Out of all the original customers')\n",
    "print(f'Not acquired: 8 weeks after first transaction {new_8wk_repeat3:.0f}% of customers had made a repeat purchase')\n",
    "print(f'Acquired: 8 weeks after first transaction {acq_8wk_repeat3:.0f}% of customers had made a repeat purchase')\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase3= pd.DataFrame(df_acq_txns[df_acq_txns['count']==3].groupby('week_diff').nunique()['customer_id']).reset_index().cumsum()\n",
    "purchase3['pcent_of_acquisitions'] = (purchase3['customer_id']/repeat_by_week.loc[:8]['cumulative_made_second_transaction'].max())*100\n",
    "purchase3.columns = ['weeks_since_transaction','cumulative_made_second_transaction','pcent']\n",
    "purchase3.set_index('weeks_since_transaction', inplace = True)\n",
    "purchase3\n",
    "\n",
    "#look at cumulative repeat for all new customers not acquired\n",
    "purchase3b = pd.DataFrame(df_new_not_acq[df_new_not_acq['count']==3].groupby('week_diff').nunique()['customer_id']).reset_index().cumsum()\n",
    "purchase3b['pcent_of_acquisitions'] = (purchase3b['customer_id']/repeat_by_week2.loc[:8]['cumulative_made_second_transaction'].max())*100\n",
    "purchase3b.columns = ['weeks_since_transaction','cumulative_made_second_transaction','pcent']\n",
    "purchase3b.set_index('weeks_since_transaction', inplace = True)\n",
    "purchase3b = purchase3b.loc[:12]\n",
    "\n",
    "new_8wk_repeat3 = purchase3b.loc[:8]['pcent'].max()\n",
    "acq_8wk_repeat3 = purchase3.loc[:8]['pcent'].max()\n",
    "\n",
    "print('Out of all the customers that made a 2nd purchase')\n",
    "print(f'Not acquired: 8 weeks after first transaction {new_8wk_repeat3:.0f}% of customers had made a repeat purchase')\n",
    "print(f'Acquired: 8 weeks after first transaction {acq_8wk_repeat3:.0f}% of customers had made a repeat purchase')\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase4= pd.DataFrame(df_acq_txns[df_acq_txns['count']==4].groupby('week_diff').nunique()['customer_id']).reset_index().cumsum()\n",
    "purchase4['pcent_of_acquisitions'] = (purchase4['customer_id']/len(offer_acquisitions))*100\n",
    "purchase4.columns = ['weeks_since_transaction','cumulative_made_second_transaction','pcent']\n",
    "purchase4.set_index('weeks_since_transaction', inplace = True)\n",
    "purchase4\n",
    "\n",
    "#look at cumulative repeat for all new customers not acquired\n",
    "purchase4b = pd.DataFrame(df_new_not_acq[df_new_not_acq['count']==4].groupby('week_diff').nunique()['customer_id']).reset_index().cumsum()\n",
    "purchase4b['pcent_of_acquisitions'] = (purchase4b['customer_id']/new_count)*100\n",
    "purchase4b.columns = ['weeks_since_transaction','cumulative_made_second_transaction','pcent']\n",
    "purchase4b.set_index('weeks_since_transaction', inplace = True)\n",
    "purchase4b = purchase4b.loc[:12]\n",
    "\n",
    "new_8wk_repeat4 = purchase4b.loc[:8]['pcent'].max()\n",
    "acq_8wk_repeat4 = purchase4.loc[:8]['pcent'].max()\n",
    "\n",
    "print(f'Not acquired: 8 weeks after first transaction {new_8wk_repeat4:.0f}% of customers had made a repeat purchase')\n",
    "print(f'Acquired: 8 weeks after first transaction {acq_8wk_repeat4:.0f}% of customers had made a repeat purchase')\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase4= pd.DataFrame(df_acq_txns[df_acq_txns['count']==5].groupby('week_diff').nunique()['customer_id']).reset_index().cumsum()\n",
    "purchase4['pcent_of_acquisitions'] = (purchase4['customer_id']/len(offer_acquisitions))*100\n",
    "purchase4.columns = ['weeks_since_transaction','cumulative_made_second_transaction','pcent']\n",
    "purchase4.set_index('weeks_since_transaction', inplace = True)\n",
    "purchase4\n",
    "\n",
    "#look at cumulative repeat for all new customers not acquired\n",
    "purchase4b = pd.DataFrame(df_new_not_acq[df_new_not_acq['count']==5].groupby('week_diff').nunique()['customer_id']).reset_index().cumsum()\n",
    "purchase4b['pcent_of_acquisitions'] = (purchase4b['customer_id']/new_count)*100\n",
    "purchase4b.columns = ['weeks_since_transaction','cumulative_made_second_transaction','pcent']\n",
    "purchase4b.set_index('weeks_since_transaction', inplace = True)\n",
    "purchase4b = purchase4b.loc[:12]\n",
    "\n",
    "new_8wk_repeat4 = purchase4b.loc[:8]['pcent'].max()\n",
    "acq_8wk_repeat4 = purchase4.loc[:8]['pcent'].max()\n",
    "\n",
    "print(f'Not acquired: 8 weeks after first transaction {new_8wk_repeat4:.0f}% of customers had made a repeat purchase')\n",
    "print(f'Acquired: 8 weeks after first transaction {acq_8wk_repeat4:.0f}% of customers had made a repeat purchase')\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-enough",
   "metadata": {},
   "source": [
    "## Revenue Impact (during offer peri\n",
    "- Total\n",
    "- per customer\n",
    "- Value of discount\n",
    "    - per customer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-juice",
   "metadata": {},
   "source": [
    "### Existing customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "#existing incremental value \n",
    "#can do this calculation at average or total level\n",
    "\n",
    "#during offer period\n",
    "during_spend = agg[agg['new_segment']=='existing'].groupby('offer_segment').agg({'total_amount':['mean','median','sum']})\n",
    "\n",
    "#pre offer period\n",
    "#first need to know the redemption segments they ended up in \n",
    "offer_period_segs = agg[['customer_id','offer_segment']].drop_duplicates()\n",
    "#by definition all customers in the pre offer period are in the existing segment but will need to attach on redemption segment to pre transactions\n",
    "pre_offer_transactions = df[df['date']<date_min][['customer_id','receipt_id','total_amount','date','updated_date']].drop_duplicates()\n",
    "pre_offer_seg = pd.merge(pre_offer_transactions,offer_period_segs, on = 'customer_id',how = 'left')\n",
    "pre_offer_seg.fillna(0, inplace = True)\n",
    "pre_spend = pre_offer_seg.groupby('offer_segment').agg({'total_amount':['mean','median','sum']})\n",
    "#need to be carefull here with null values -> where customers do not transact in offer period \n",
    "#and with what type of average being used\n",
    "print(pre_spend)\n",
    "print(during_spend)\n",
    "\n",
    "#divide by the number of days the offer period was live and the number of days of pre period to make comparable\n",
    "pre_days = (df_during.date.min() - pre_offer_transactions.date.min()).days\n",
    "during_days = (df_during.date.max() - df_during.date.min()).days\n",
    "\n",
    "print('\\n')\n",
    "print(f'The number of days in the pre period is {pre_days}')\n",
    "print(f'The number of days in the offer period is {during_days}')\n",
    "print('\\n')\n",
    "print('Total amount per days pre:')\n",
    "pre_spend_daily = pre_spend/pre_days\n",
    "print(pre_spend_daily)\n",
    "print('\\n')\n",
    "print('Total amount per days offer:')\n",
    "during_spend_daily = during_spend/during_days\n",
    "print(during_spend_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate change in spend for redeemers and non-redeemers\n",
    "redeemer_change = during_spend_daily['total_amount']['median']['redeemer'] - pre_spend_daily['total_amount']['median']['redeemer']\n",
    "pcent_redeemer_change = redeemer_change/(pre_spend_daily['total_amount']['median']['redeemer'])\n",
    "\n",
    "non_redeemer_change = during_spend_daily['total_amount']['median']['non-redeemer'] - pre_spend_daily['total_amount']['median']['non-redeemer']\n",
    "pcent_non_redeemer_change = non_redeemer_change/(pre_spend_daily['total_amount']['median']['non-redeemer'])\n",
    "\n",
    "if pcent_redeemer_change**2 > pcent_non_redeemer_change**2:\n",
    "    larger_smaller = 'larger'\n",
    "else: \n",
    "    larger_smaller = 'smaller'\n",
    "    \n",
    "if pcent_redeemer_change > 0:\n",
    "    increase_decrease = 'increase'\n",
    "else:\n",
    "    increase_decrease = 'decrease'\n",
    "\n",
    "incr_pcent = pcent_redeemer_change-pcent_non_redeemer_change\n",
    "avg_pre_spend_redeemer = pre_spend_daily['total_amount']['median']['redeemer']/100\n",
    "incr_spend = (avg_pre_spend_redeemer * incr_pcent)\n",
    "\n",
    "print('Existing Customers \\n')\n",
    "print(f'The redeemers of the offer have a {larger_smaller} proportional {increase_decrease} in daily average spend than the non-redeemers between the pre period and offer period')\n",
    "print(f'The perentage change in spend between periods is {pcent_redeemer_change*100:.0f}% in the redeemer group & {pcent_non_redeemer_change*100:.0f}% in the non-redeemer group')\n",
    "print(f'Incremental accounts for {incr_pcent*100:.0f}% of spend in the redeemer group')\n",
    "print(f'The average pre spend per redeemer per day was £{avg_pre_spend_redeemer:.2f}, resulting in a daily incremental spend per redeemer of £{incr_spend:.2f}')\n",
    "#incr_spend_total = incr_spend*total_cust*(during_days/pre_days)\n",
    "incr_spend_total = incr_spend*total_cust*30\n",
    "print(f'Over the offer measurement period of {30} days, this is a total incremental spend of £{incr_spend_total:.0f} across the {existing_cust} customers')\n",
    "print(f'Or £{(incr_spend_total/existing_cust):.2f} per customer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import style\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.sans-serif'] = 'Akkurat Pro'\n",
    "matplotlib.rcParams['font.serif'] = 'Vesterbro'\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.size'] = '15'\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (50, 15)\n",
    "matplotlib.rcParams['figure.titlesize'] = '25'\n",
    "\n",
    "matplotlib.rcParams['axes.titlesize'] = '25'\n",
    "matplotlib.rcParams['axes.labelsize'] = '15'\n",
    "matplotlib.rcParams['axes.titlepad'] = '25'\n",
    "matplotlib.rcParams['axes.labelpad'] = '30'\n",
    "matplotlib.rcParams['xtick.labelsize'] = '15'\n",
    "matplotlib.rcParams['ytick.labelsize'] = '20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick plot of difference to help understanding\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (12,7))\n",
    "rp = pre_spend_daily['total_amount']['median']['redeemer']/100\n",
    "rd = during_spend_daily['total_amount']['median']['redeemer']/100\n",
    "nrp = pre_spend_daily['total_amount']['median']['non-redeemer']/100\n",
    "nrd = during_spend_daily['total_amount']['median']['non-redeemer']/100\n",
    "x = ['redeemer pre','redeeemer during','non-redeeemer pre','non-redeemer during']\n",
    "y = pd.Series([rp,rd,nrp,nrd])\n",
    "\n",
    "chart = plt.bar(x,y)\n",
    "chart[0].set_color('mint')\n",
    "chart[1].set_color('green')\n",
    "chart[2].set_color('mint')\n",
    "chart[3].set_color('pink')\n",
    "plt.title('Existing customers average daily spend by redeemer group and offer period', size = 18)\n",
    "plt.ylabel('Average Daily Spend (£)', size = 15)\n",
    "plt.xlabel('Segment', size = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is the difference significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should we be only looking at the spend after taking out the offer or for the wohle offer period?\n",
    "#---> i think this is OK because if the offer was at the end, it woul dhave less time to take effect so have a smaller impact on result?\n",
    "# but what id there was another offer than increased spend?\n",
    "# ---> the non-redeeming frgroup could have also taken out this offer. \n",
    "#if after the offer, makes it more difficult to do redeemer/non-redeemer compariso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-princeton",
   "metadata": {},
   "source": [
    "### New customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to find out the average number of days each new customer was active for in the measurement period\n",
    "new_cust_first_txn = df_during[(df_during.new_segment=='new')&(df_during['count']==1)][['customer_id','date','offer_segment']].copy()\n",
    "#work uot at what point in the measurement period, the new customer joined and began transacting \n",
    "new_cust_first_txn['days_active'] = (date_max - new_cust_first_txn['date']).astype('timedelta64[D]')\n",
    "#what is the average active days for new customers in each redemption group \n",
    "new_days_active = new_cust_first_txn.groupby('offer_segment').agg({'days_active':['mean','median']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new customers spend \n",
    "\n",
    "#during offer period\n",
    "during_spend_new = agg[agg['new_segment']=='new'].groupby('offer_segment').agg({'total_amount':['mean','median','sum']})\n",
    "daily_avg_spend_new = during_spend_new['total_amount']['median']/new_days_active['days_active']['median']\n",
    "daily_incr_new = (daily_avg_spend_new['redeemer'] - daily_avg_spend_new['non-redeemer'])/100\n",
    "incr_spend_new = daily_incr_new*new_cust*30\n",
    "\n",
    "print(f'For new customers, daily average incremetal spend was £{daily_incr_new:.2f} in the redeemer group')\n",
    "print(f'')\n",
    "print(f'Over the offer measurement period of {30} days, this is a total incremental spend of £{incr_spend_new:.2f} across the {new_cust:.0f} customers')\n",
    "print(f'Or £{incr_spend_new/new_cust:.2f} per customer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick plot of difference to help understanding\n",
    "\n",
    "plt.figure(figsize = (12,7))\n",
    "rd = daily_avg_spend_new['redeemer']/100\n",
    "nrd = daily_avg_spend_new['non-redeemer']/100\n",
    "x = ['redeemer','non-redeeemer']\n",
    "y = pd.Series([rd,nrd])\n",
    "\n",
    "chart = plt.bar(x,y)\n",
    "chart[0].set_color('green')\n",
    "chart[1].set_color('pink')\n",
    "plt.title('New customers average daily spend during the offer period', size = 18)\n",
    "plt.ylabel('Average Daily Spend (£)', size = 15)\n",
    "plt.xlabel('Segment', size = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-adapter",
   "metadata": {},
   "source": [
    "## Acquired customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acq_txns['lagged_date'] = df_acq_txns.groupby('customer_id')['date'].shift(1)\n",
    "df_acq_txns['date_diff'] = (df_acq_txns['date'] - df_acq_txns['lagged_date']).dt.days\n",
    "df_acq_txns['week_diff'] = np.ceil(df_acq_txns.date_diff/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "acq = agg[agg['new_segment']=='acquired']\n",
    "first_date = pd.DataFrame(df_during[df_during['new_segment']=='acquired'].groupby('customer_id').date.min())\n",
    "new_df = pd.merge(acq,first_date, on = 'customer_id', how = 'left')\n",
    "new_df['max_date'] = date_max\n",
    "new_df['date_diff'] = (new_df.max_date - new_df.date).dt.days\n",
    "roi_monthly_total = ((new_df['total_amount']/new_df['date_diff'])*30).sum()\n",
    "roi_monthly_avg = ((new_df['total_amount']/new_df['date_diff'])*30).mean()\n",
    "\n",
    "print(roi_monthly_total)\n",
    "print(roi_monthly_avg)\n",
    "\n",
    "#need the number of days they were active = max-date - first_transaction_date\n",
    "#calcaulte total monthly spend \n",
    "#monthly spend = ROI contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg[agg['new_segment']=='acquired'].nunique()['customer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg[agg['new_segment']=='acquired']['total_amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "during_spend_acquired = agg[agg['new_segment']=='acquired']['total_amount'].sum()\n",
    "acquired_cust = agg[agg['new_segment']=='acquired'].nunique()['customer_id']\n",
    "\n",
    "print(f'For aquired customers, all spend is attributed to the offer')\n",
    "print(f'Assumption is that the offer drove them to start transacting with the retailer')\n",
    "print('\\n')\n",
    "print(f'Over the offer measurement period of {during_days} days, this is a total spend of £{during_spend_acquired:.2f} across the {acquired_cust:.0f} customers')\n",
    "print(f'Or £{during_spend_acquired/acquired_cust:.2f} per customer')\n",
    "print(f'Or £{(during_spend_acquired/acquired_cust)/d:.2f} per customer per day')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-commodity",
   "metadata": {},
   "source": [
    "### Total Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_incr_rev = incr_spend_new + incr_spend_total \n",
    "total_incr_rev_cust = total_incr_rev/total_cust\n",
    "\n",
    "print(f'The total incremental revenue from this offer over the measurement period is £{total_incr_rev:.0f}')\n",
    "print(f'Per redeemer this is £{total_incr_rev_cust:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-thomson",
   "metadata": {},
   "source": [
    "### Total Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "#= sum of redeemer price \n",
    "redeemer_receipts_during = df_during[df_during.new_segment.isin(['new','existing'])]['receipt_id'].unique()\n",
    "\n",
    "total_cost = (df_off[df_off['receipt_id'].isin(redeemer_receipts_during)]['price']*-1).sum()/100\n",
    "total_cost_cust = total_cost/total_cust\n",
    "\n",
    "print(f'The total discount given out over the offer measurement period is £{total_cost}')\n",
    "print(f'Per redeemer this is £{total_cost_cust:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-volume",
   "metadata": {},
   "source": [
    "# Cost acquired only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost for acquired:\n",
    "\n",
    "\n",
    "redeemer_receipts_during = df_during[df_during['new_segment'] == 'acquired']['receipt_id'].unique()\n",
    "\n",
    "total_cost_acq = (df_off[df_off['receipt_id'].isin(redeemer_receipts_during)]['price']*-1).sum()/100\n",
    "total_cost_cust_acq = total_cost/total_cust\n",
    "\n",
    "print(f'The total discount given out over the offer measurement period is £{total_cost}')\n",
    "print(f'Per redeemer this is £{total_cost_cust:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-helicopter",
   "metadata": {},
   "source": [
    "# ROI acquired only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Acquired customers monthly revenue is £{roi_monthly_total:.2f}')\n",
    "print(f'Acquired customers cost is £{total_cost_acq:.2f}')\n",
    "\n",
    "print((roi_monthly_total - total_cost_acq))\n",
    "\n",
    "ROI_acq = (roi_monthly_total/total_cost_acq)\n",
    "print(f'Return on investment is {ROI_acq:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-collect",
   "metadata": {},
   "source": [
    "## ROI not acquired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = (total_incr_rev/total_cost)\n",
    "\n",
    "\n",
    "print((total_incr_rev - total_cost))\n",
    "\n",
    "print(f'Previous customers monthly increase in revenue is £{total_incr_rev:.2f}')\n",
    "print(f'Previous customers cost is £{total_cost:.2f}')\n",
    "print(f'Return on investment is {ROI:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-sellers",
   "metadata": {},
   "source": [
    "## ATV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_metrics = agg2['ATV']\n",
    "\n",
    "agg\n",
    "ATV_redeemer = agg[agg['offer_segment']=='redeemer']['amount'].median()/100\n",
    "ATV_non_redeemer = agg[agg['offer_segment']=='non-redeemer']['amount'].median()/100\n",
    "\n",
    "print(f'Redeemers have an average transaction value of £{ATV_redeemer:.2f} during the offer period')\n",
    "print(f'Non-redeemers have an average transaction value of £{ATV_non_redeemer:.2f} time during the offer period')\n",
    "print('\\n')\n",
    "\n",
    "print('More detailed breakdown of ATV:')\n",
    "print(v_metrics)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average transaction value of redemmers total is :\n",
    "agg[agg['offer_segment']=='redeemer']['amount'].median()/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg['prev_segment']= np.where(agg['new_segment'].isin(['existing','new']),'previous','acquired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg3 = agg.groupby(['offer_segment','prev_segment']).agg({'customer_id'  : ['nunique']\n",
    "                                                                    ,'frequency'  : ['mean','median']\n",
    "                                                                    ,'total_amount': ['sum','mean','median']\n",
    "                                                                    , 'amount':['mean','median']\n",
    "                                                                    , 'adjusted_basket_size':['mean','median']\n",
    "                                                                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#£ ATV for previosu vs acquired\n",
    "agg3.loc['redeemer']['amount']['median']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg3.loc['redeemer']['customer_id']['nunique']/(agg3.loc['redeemer']['customer_id']['nunique'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-eclipse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-prompt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-founder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "intensive-gibson",
   "metadata": {},
   "source": [
    "## Basket Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now can summarise by segments the average basket size \n",
    "b_metrics = agg2['ABS']\n",
    "\n",
    "ABS_redeemer = agg[agg['offer_segment']=='redeemer']['adjusted_basket_size'].median()\n",
    "ABS_non_redeemer = agg[agg['offer_segment']=='non-redeemer']['adjusted_basket_size'].median()\n",
    "\n",
    "print('Excluding the item on offer from the basket:')\n",
    "print(f'Redeemers have an average basket size of {ABS_redeemer:.2f} during the offer period')\n",
    "print(f'Non-redeemers have an average basket size of {ABS_non_redeemer:.2f} time during the offer period')\n",
    "print('\\n')\n",
    "\n",
    "print('More detailed breakdown of Basket Size:')\n",
    "print(b_metrics)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-blackjack",
   "metadata": {},
   "source": [
    "## Time of Day/ Day of Week Redemption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_during['weekday_name'] = df_during['transaction_date'].dt.day_name()\n",
    "df_during['weekday'] = df_during['transaction_date'].dt.weekday\n",
    "df_during['time_hour'] = df_during['transaction_date'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = pd.DataFrame(df_during[df_during['redemption_count']>0].groupby(['weekday','weekday_name']).nunique()['receipt_id'])\n",
    "days.columns = ['unique_receipts']\n",
    "days.reset_index('weekday', drop = True, inplace = True)\n",
    "top_day = days.sort_values(by = 'unique_receipts',ascending = False).head(1)\n",
    "print(f'Overall, the most popular day to redeem is {top_day.index.values[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split by new and existing redeemers\n",
    "days_seg = pd.DataFrame(df_during[df_during['redemption_count']>0].groupby(['new_segment','weekday','weekday_name']).nunique()['receipt_id'])\n",
    "days_seg.columns = ['unique_receipts']\n",
    "days_seg.reset_index('weekday', drop = True, inplace = True)\n",
    "top_day_existing = days_seg.loc['existing'].sort_values(by = 'unique_receipts',ascending = False).head(1).index.values[0]\n",
    "top_day_new = days_seg.loc['new'].sort_values(by = 'unique_receipts',ascending = False).head(1).index.values[0]\n",
    "top_day_acquired = days_seg.loc['acquired'].sort_values(by = 'unique_receipts',ascending = False).head(1).index.values[0]\n",
    "print(f'The most popular day for existing customers is {top_day_existing}')\n",
    "print(f'The most popular day for new customers is {top_day_new}')\n",
    "print(f'The most popular day for acquired customers is {top_day_acquired}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['xtick.labelsize'] = '30'\n",
    "matplotlib.rcParams['ytick.labelsize'] = '30'\n",
    "\n",
    "\n",
    "\n",
    "x = days.index.values\n",
    "y = days['unique_receipts']\n",
    "plt.bar(x,y,color = 'mint')\n",
    "plt.title('Offer redemptions by day of week', size = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = days_seg.loc['existing'].index.values\n",
    "y1 = ((days_seg.loc['existing']/days_seg.loc['existing'].sum())*100)['unique_receipts']\n",
    "x2 = days_seg.loc['new'].index.values\n",
    "y2 = ((days_seg.loc['new']/days_seg.loc['new'].sum())*100)['unique_receipts']\n",
    "x3 = days_seg.loc['acquired'].index.values\n",
    "y3 = ((days_seg.loc['acquired']/days_seg.loc['acquired'].sum())*100)['unique_receipts']\n",
    "plt.plot(x1,y1,color = 'mint', label = 'existing',marker='o', linestyle='dashed',linewidth=2, markersize=12)\n",
    "plt.plot(x2,y2,color = 'green', label = 'new',marker='o', linestyle='dashed',linewidth=2, markersize=12)\n",
    "plt.plot(x3,y3,color = 'black', label = 'acquired',marker='o', linestyle='dashed',linewidth=2, markersize=12)\n",
    "#plt.title('Offer redemptions by day of week and segment', size = 40, pad = 10)\n",
    "plt.legend(fontsize = 30)\n",
    "plt.ylabel('% of segment receipts', size = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = df_during[df_during['redemption_count']>0].groupby(['time_hour']).nunique()['receipt_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours.columns = ['unique_receipts']\n",
    "top_hour = hours.sort_values(ascending = False).head(1)\n",
    "print(f'The most popular hour is {top_hour.index.values[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['xtick.labelsize'] = '30'\n",
    "matplotlib.rcParams['ytick.labelsize'] = '30'\n",
    "\n",
    "x = hours.index.values\n",
    "y = hours\n",
    "plt.bar(x,y,color = 'tmnt')\n",
    "plt.title('Offer redemptions by hour', size = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split by new and existing redeemers\n",
    "hours_seg = pd.DataFrame(df_during[df_during['redemption_count']>0].groupby(['new_segment','time_hour']).nunique()['receipt_id'])\n",
    "hours_seg.columns = ['unique_receipts']\n",
    "top_hour_existing = hours_seg.loc['existing'].sort_values(by = 'unique_receipts',ascending = False).head(1).index.values[0]\n",
    "top_hour_new = hours_seg.loc['new'].sort_values(by = 'unique_receipts',ascending = False).head(1).index.values[0]\n",
    "top_hour_acq = hours_seg.loc['acquired'].sort_values(by = 'unique_receipts',ascending = False).head(1).index.values[0]\n",
    "\n",
    "print(f'The most popular hour of day for existing customers is {top_hour_existing}')\n",
    "print(f'The most popular hour of day for new customers is {top_hour_new}')\n",
    "print(f'The most popular hour of day for new customers is {top_hour_acq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = hours_seg.loc['existing'].index.values\n",
    "y1 = ((hours_seg.loc['existing']/hours_seg.loc['existing'].sum())*100)['unique_receipts']\n",
    "x2 = hours_seg.loc['new'].index.values\n",
    "y2 = ((hours_seg.loc['new']/hours_seg.loc['new'].sum())*100)['unique_receipts']\n",
    "x3 = hours_seg.loc['acquired'].index.values\n",
    "y3 = ((hours_seg.loc['acquired']/hours_seg.loc['acquired'].sum())*100)['unique_receipts']\n",
    "plt.plot(x1,y1,color = 'mint', label = 'existing',marker='o', linestyle='dashed',linewidth=2, markersize=12)\n",
    "plt.plot(x2,y2,color = 'green', label = 'new',marker='o', linestyle='dashed',linewidth=2, markersize=12)\n",
    "plt.plot(x3,y3,color = 'black', label = 'acquired',marker='o', linestyle='dashed',linewidth=2, markersize=12)\n",
    "#plt.title('Offer redemptions by day of week and segment', size = 40, pad = 10)\n",
    "plt.legend(fontsize = 30)\n",
    "plt.ylabel('% of segment receipts', size = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrix of day and hour\n",
    "\n",
    "day_hours = pd.DataFrame(df_during[df_during['redemption_count']>0].groupby(['weekday','weekday_name','time_hour']).nunique()['receipt_id'])\n",
    "day_hours.columns =['unique_receipts']\n",
    "#day_hours.reset_index('weekday',drop=True,inplace = True)\n",
    "day_hours_unstack = day_hours.unstack().fillna(0)\n",
    "day_hours_unstack.reset_index('weekday',drop=True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_hours_unstack.style.background_gradient(cmap='BuGn', axis = None).set_precision(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-history",
   "metadata": {},
   "source": [
    "## Repeat Redemptions\n",
    "### Offer Repeat Rate\n",
    "    - new\n",
    "    - existing\n",
    "    - by timeframe (e.g. day, week, month depending on length of offer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_reds = pd.DataFrame(df_during[df_during.receipt_id.isin(off_receipts)].groupby(['new_segment','customer_id'])['receipt_id'].nunique().reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_reds.groupby('new_segment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "existing_redeemers = repeat_reds[repeat_reds['new_segment']=='existing']['customer_id'].nunique()\n",
    "rep_existing_redeemers = repeat_reds[(repeat_reds['new_segment']=='existing') & (repeat_reds['receipt_id']>1)]['customer_id'].nunique()\n",
    "\n",
    "new_redeemers = repeat_reds[repeat_reds['new_segment']=='new']['customer_id'].nunique()\n",
    "rep_new_redeemers = repeat_reds[(repeat_reds['new_segment']=='new') & (repeat_reds['receipt_id']>1)]['customer_id'].nunique()\n",
    "\n",
    "acq_redeemers = repeat_reds[repeat_reds['new_segment']=='acquired']['customer_id'].nunique()\n",
    "rep_acq_redeemers = repeat_reds[(repeat_reds['new_segment']=='acquired') & (repeat_reds['receipt_id']>1)]['customer_id'].nunique()\n",
    "\n",
    "pcent_existing = (rep_existing_redeemers/existing_redeemers)*100\n",
    "pcent_new = (rep_new_redeemers/new_redeemers)*100\n",
    "pcent_acq = (rep_acq_redeemers/acq_redeemers)*100\n",
    "\n",
    "print(f'A total of {len(off_receipts)} redemptions were made on the offer')\n",
    "print('\\n')\n",
    "print(f'The percentage of existing redeemers that made more than 1 redemption is {pcent_existing:.2f}% ({rep_existing_redeemers}/{existing_redeemers})')\n",
    "print(f'The percentage of new redeemers that made more than 1 redemption is {pcent_new:.2f}% ({rep_new_redeemers}/{new_redeemers})')\n",
    "print(f'The percentage of acquired redeemers that made more than 1 redemption is {pcent_acq:.2f}% ({rep_acq_redeemers}/{acq_redeemers})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-sussex",
   "metadata": {},
   "source": [
    "# ***Post offer analysis***:\n",
    "\n",
    "- Long-term impact on frequency of customers redeeming the offer\n",
    "    - Time series data\n",
    "    - vs non-redeemers\n",
    "- Long term impact of ATV of customers redeeming the offer\n",
    "    - vs non-redeemers\n",
    "- Retention of customers who have redeemed the offer vs baseline\n",
    "- Segment of customers acquired via the offer\n",
    "    - % in each segment vs expected %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "redemption_segment = agg[['offer_segment','customer_id']]\n",
    "df_red_seg = pd.merge(df,redemption_segment, on = 'customer_id',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red_seg['offer_segment'] = df_red_seg['offer_segment'].fillna('non-redeemer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red_seg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red_seg.groupby(['customer_id')."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing_env",
   "language": "python",
   "name": "testing_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
