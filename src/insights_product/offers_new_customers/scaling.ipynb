{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "smaller-silicon",
   "metadata": {},
   "source": [
    "# Scaling Offers Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-packing",
   "metadata": {},
   "source": [
    "### What this code do?\n",
    "- scales the number of customers & transaction value metrics in the redeemer and non redeemer group by comparing transaction volume and amount to that of unmatched retailer transactions\n",
    "\n",
    "### What assumptions do we have to make for offers metrics when scaling?\n",
    "- the new/existing segment splits (percent of customers in each group) are consistent with Flux customers for the retailer\n",
    "- the transaction frequency per redemption group (reddemer vs non_redeemer) is consistent with Flux (no scaler)\n",
    "- the scaler on average transaction amount between flux and the redeemer is the same across redeemer groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.database import query_from_file\n",
    "import datetime\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "path = '/Users/jennamiles/Documents/credentials'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is from database.py\n",
    "#need to update in utils because of directory issue\n",
    "import os\n",
    "from psycopg2 import connect\n",
    "from pandas import read_sql\n",
    "\n",
    "def query(sql_statement: str, **kwargs):\n",
    "    with open(f'{path}', 'r') as credentials:\n",
    "        connection = connect(credentials.read())\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        if len(kwargs) > 0:\n",
    "            dataframe = read_sql(sql_statement.format(**kwargs), connection)\n",
    "        else:\n",
    "            dataframe = read_sql(sql_statement, connection)\n",
    "\n",
    "        assert len(dataframe) > 0, 'query returned no results'\n",
    "        return dataframe\n",
    "    \n",
    "def query_from_file(sql_file: str, **kwargs):\n",
    "    with open(sql_file, 'r') as f:\n",
    "        return query(f.read(), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "funny-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the retailer, the offer\n",
    "retailer = 'pure'\n",
    "offer_name = 'free coffee yellow'\n",
    "#could use offer sku here instead of offer if easier\n",
    "#may also want ot add in location id -> in this case makes the scalers by location too \n",
    "location_id = ''\n",
    "\n",
    "sql_flux = 'pure_txns.sql'\n",
    "sql_retailer = 'pure_all.sql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "communist-contributor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query took 313.14 seconds\n"
     ]
    }
   ],
   "source": [
    "#bring in the transactions for both flux and all transactions \n",
    "#read in pure data from SQL query:\n",
    "start = time.time()\n",
    "df = query_from_file(sql_flux)\n",
    "df_all = query_from_file(sql_retailer)\n",
    "end = time.time()\n",
    "query_time = end-start\n",
    "print(f\"Query took {query_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "vital-kidney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start date is 2019-11-27 07:04:06+00:00\n",
      "end date is 2021-04-12 08:23:00+00:00\n"
     ]
    }
   ],
   "source": [
    "#flag redemption transactions \n",
    "df['redemption_flag'] = np.where(df['name'].str.lower() == offer_name,1,0)\n",
    "# need to match onto items if possible here\n",
    "df_all['redemption_flag'] = np.where(df_all['name'].str.lower() == offer_name,1,0)\n",
    "\n",
    "#flag the offer period and pre-period\n",
    "df_all['date'] = df_all.adjusted_transaction_date.dt.date\n",
    "df['date'] = df.transaction_date.dt.date\n",
    "\n",
    "start = df_all[df_all['redemption_flag']==1].adjusted_transaction_date.min()\n",
    "end = df_all[df_all['redemption_flag']==1].adjusted_transaction_date.max()\n",
    "print(f'start date is {start}')\n",
    "print(f'end date is {end}')\n",
    "\n",
    "df_all['offer_period'] = np.where(((df_all['date']>= start) & (df_all['date']<= end)),1,0)\n",
    "df_all['pre_offer_period'] = np.where((df_all['date']<= start),1,0)\n",
    "\n",
    "df['offer_period'] = np.where(((df['date']>= start) & (df['date']<= end)),1,0)\n",
    "df['pre_offer_period'] = np.where((df['date']<= start),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "crucial-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer scalers during offer period\n",
    "# 1) Flux data\n",
    "transactions_flux = df[df.offer_period == 1].nunique()['receipt_id']\n",
    "redemptions_flux = df[(df.redemption_flag == 1) & (df.offer_period == 1)].nunique()['receipt_id']\n",
    "redemption_receipts = df[(df.redemption_flag == 1) & (df.offer_period == 1)]['receipt_id'].unique()\n",
    "non_redemptions_flux = df[(~df.receipt_id.isin(redemption_receipts)) & (df.offer_period == 1)].nunique()['receipt_id']\n",
    "redeemers_flux = df[(df.redemption_flag == 1) & (df.offer_period == 1)].nunique()['customer_id']\n",
    "redeemers = df[(df.redemption_flag == 1) & (df.offer_period == 1)]['customer_id'].unique()\n",
    "non_redeemers_flux = df[(~df.customer_id.isin(redeemers)) & (df.offer_period == 1)].nunique()['customer_id']\n",
    "customers_flux = df[df.offer_period == 1].nunique()['customer_id']\n",
    "redeemers_receipts_flux = df[(df.offer_period == 1)&(df.customer_id.isin(redeemers))].nunique()['receipt_id']\n",
    "non_redeemers_receipts_flux = df[(df.offer_period == 1)&(~df.customer_id.isin(redeemers))].nunique()['receipt_id']\n",
    "# 2) Retailer data\n",
    "transactions_retailer = df_all[df_all.offer_period == 1].nunique()['txn_id']\n",
    "redemptions_retailer = df_all[(df_all.redemption_flag == 1) & (df_all.offer_period == 1)].nunique()['txn_id']\n",
    "redemption_txns = df_all[(df_all.redemption_flag == 1) & (df_all.offer_period == 1)]['txn_id'].unique()\n",
    "non_redemptions_retailer = df_all[(~df_all.txn_id.isin(redemption_txns)) & (df_all.offer_period == 1)].nunique()['txn_id']\n",
    "# 3) Scalers\n",
    "redemptions_scaler = redemptions_retailer/redemptions_flux\n",
    "non_redemptions_scaler = non_redemptions_retailer/non_redemptions_flux\n",
    "# 4) Retailer customer estimates\n",
    "# multiplying by transactions scaler the same as estimating atf and diving transactions by that\n",
    "est_redeemers_retailer = np.floor(redeemers_flux*redemptions_scaler)\n",
    "est_non_redeemers_retailer = np.floor(non_redeemers_flux*non_redemptions_scaler)\n",
    "est_customers = est_redeemers_retailer+est_non_redeemers_retailer #should be more accurate than having a scaler across all transactions\n",
    "# 5) transaction value scalers - redeemer and non-redeemer group treated the same here - can't identify all redemeer transactions (includes non redemption redeemer transactions) for retailer\n",
    "ATV_flux = df[df.offer_period == 1][['receipt_id','total_amount']].drop_duplicates()['total_amount'].agg({'mean','median'})\n",
    "ATV_retailer = df_all[df_all.offer_period == 1][['txn_id','amount']].drop_duplicates()['amount'].agg({'mean','median'})\n",
    "ATV_scalers = ATV_retailer/ATV_flux\n",
    "mean_atv_scaler = ATV_scalers['mean']\n",
    "median_atv_scaler = ATV_scalers['median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "amateur-communist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note:\n",
      "ATF is assumed to be the same across retailer as seen in flux per redemption groups\n",
      "This means the scaler for transactions is the same as for customers\n",
      "\n",
      "\n",
      "During the offer period:\n",
      "ATF redeemers is 11.99\n",
      "ATF non-redeemers is 3.05\n",
      "Redeemers and redemptions scaler is 36.42\n",
      "Non-redemptions and non-redeemers scaler is 53.62\n",
      "ATV scaler for mean values is 1.0991\n",
      "ATV scaler for median values is 1.0227\n",
      "Total redemptions during offer period is 11217\n",
      "Total transactions during offer period is 1329235\n",
      "Total estimated redeemers during offer period is 5717\n",
      "Total estimated customers during offer period is 410040\n"
     ]
    }
   ],
   "source": [
    "print('Note:')\n",
    "print('ATF is assumed to be the same across retailer as seen in flux per redemption groups')\n",
    "print('This means the scaler for transactions is the same as for customers')\n",
    "print('\\n')\n",
    "print('During the offer period:')\n",
    "print(f'ATF redeemers is {redeemers_receipts_flux/redeemers_flux:.2f}')\n",
    "print(f'ATF non-redeemers is {non_redeemers_receipts_flux/non_redeemers_flux:.2f}')\n",
    "print(f'Redeemers and redemptions scaler is {redemptions_scaler:.2f}')\n",
    "print(f'Non-redemptions and non-redeemers scaler is {non_redemptions_scaler:.2f}')\n",
    "print(f'ATV scaler for mean values is {mean_atv_scaler:.4f}')\n",
    "print(f'ATV scaler for median values is {median_atv_scaler:.4f}')\n",
    "print(f'Total redemptions during offer period is {redemptions_retailer}')\n",
    "print(f'Total transactions during offer period is {transactions_retailer}')\n",
    "print(f'Total estimated redeemers during offer period is {est_redeemers_retailer:.0f}')\n",
    "print(f'Total estimated customers during offer period is {est_customers:.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-nature",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
